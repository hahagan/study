### test-and-set

[主要参考](https://zhuanlan.zhihu.com/p/125742057)与维基百科

```
#define LOCKED 1

int test_and_set(int* lockPtr) {
    int oldValue;

    // -- Start of atomic segment --
    // This should be interpreted as pseudocode for illustrative purposes only.
    // Traditional compilation of this code will not guarantee atomicity, the
    // use of shared memory (i.e., non-cached values), protection from compiler
    // optimizations, or other required properties.
    oldValue = *lockPtr;
    *lockPtr = LOCKED;
    // -- End of atomic segment --

    return oldValue;
}

function Lock(boolean *lock) { 
    while (test_and_set(lock) == 1); 
}
```

汇编对该代码的的可能实现

```
enter_region:        ; A "jump to" tag; function entry point.

  tsl reg, flag      ; Test and Set Lock; flag is the
                     ; shared variable; it is copied
                     ; into the register reg and flag
                     ; then atomically set to 1.

  cmp reg, #0        ; Was flag zero on entry_region?

  jnz enter_region   ; Jump to enter_region if
                     ; reg is non-zero; i.e.,
                     ; flag was non-zero on entry.

  ret                ; Exit; i.e., flag was zero on
                     ; entry. If we get here, tsl
                     ; will have set it non-zero; thus,
                     ; we have claimed the resource
                     ; associated with flag.

leave_region:
  move flag, #0      ; store 0 in flag
  ret                ; return to caller
```

问题：该实现为什么能保证线程安全，实现锁的能力？多线程执行时是否可能会出现以下状态，如果不会，为什么？两个线程同时运行到"<--"所指指令，此时由于线程2虽然获得了锁权限，但是尚未设置flag值，那么令一个线程也会获得flag数据，且为0。那么将会导致两个线程都是获得锁权限，是什么原理确保了不会出现以下情况。

答：

1. tsl指令为原子指令，使用该指令(硬件或某种机制)确保在单处理器系统中不会发生线程切换。
2. 多处理器中该实现可能会出现描述中的情况 ，因此在X86平台上，cpu提供了在指令执行期间对总线加锁的手段。CPU芯片上有一条引线#HLOCK pin，如果汇编语言的程序中在一条指令前面加上前缀"LOCK"，经过汇编以后的机器代码就使CPU在执行这条指令的时候把#HLOCK pin的电位拉低，持续到这条指令结束时放开，从而把总线锁住，这样同一总线上别的CPU就暂时不能通过总线访问内存了，保证了这条指令在多处理器环境中的原子性。

```
enter_region：
	tsl reg, flag		; P1,flag = 0					tsl reg, flag
	cmp reg, #0			; reg is non-zero <--			cmp reg, #0
	jnz enter_region									jnz enter_region
	ret													ret						; P2 get flag is zero	<---
leave_region:										leave_region:
	move flag, #0										move flag, #0		
	ret													ret
```

#### test-test-and-set

```
boolean locked := false // shared lock variable
procedure EnterCritical() {
  do {
    while (locked == true) yield(); // lock looks busy so yield to scheduler
  } while TestAndSet(locked) // actual atomic locking
}
procedure TestAndSet(lock) {
   boolean initial = lock;
   lock = true;
   return initial;
 }
```

#### 基于共享总线的计算机结构

[主要参考](https://zhuanlan.zhihu.com/p/125742057)

基本概念

1. cpu可以在从西安上发送广播消息，可以被连接在总线上的其他设备接收

2. 同一时刻只要能有一个cpu占用总线

   ![](https://pic2.zhimg.com/80/v2-639e84100899b464fcfeb2f7a4dcb2d1_720w.jpg)

cpu的内存读写

1. cpu读取数据时会通过总线向内存读取数据，复制到本地cache中

2. cpu修改数据时，不能直接对数据进行修改，各个cpu可能存在该数据的拷贝
3. 写数据cpu需要向总线发送修改信息，希望其他cpu将数据从缓存中移除
4. 其他cpu将缓存内的对于数据移除
5. 写数据cpu执行数据写指令

##### ttas的总线流量风暴

​	在ttas算法释放锁时，会将对应内存数据修改，此时会触发各个cpu的缓存miss问题，其他此时各个cpu会触发一次tas，引发总线流量风暴

#### tas与ttas的性能差异

ttas性能高于tas，但是保证了相同的一致性。原因在于tas的每次执行都会往总线发送一个广播消息，标识执行tas指令的cpu需要膝盖数据，使得其他cpu的数据副本失效。所以总线被一个线程占用后，会延迟其他所有线程，包括没有等待锁的线程。

另一个原因时由于其他的线程本地缓存被移除，再次读取时会触发cache miss。

**tas算法产生大量总线流量，从而延迟其他线程**

ttas在代码上首先进行test，该步骤仅会从本地缓存中读取数据，从而减少了总线的占用。

#### backoff lock

基本概念：

1. 争用：多个线程试图获取同一个锁
2. 高争用：大量争用的线程
3. 低争用：与高争用相反

重要结论：如果其他某个线程在第一步和第二部间获取锁，那么该锁极有可能存在高争用（为什么）

所以为了避免高争用的情形，将线程后退一段时间，给正在竞争的线程结束的机会。

```
boolean locked := false // shared lock variable
procedure EnterCritical() {
  do {
    yield()	//yild or sleep a random time if can't get lock
    while (locked == true) yield(); // lock looks busy so yield to scheduler
  } while TestAndSet(locked) // actual atomic locking
}
procedure TestAndSet(lock) {
   boolean initial = lock;
   lock = true;
   return initial;
 }
```

该实现的性能与后退的时间窗口选取有较大的关系。而该值与处理器的个数也有关系。



### compare-and-test

```
int compare_and_swap(int* reg, int oldval, int newval)
{
    ATOMIC();
    int old_reg_val = *reg;
    if (old_reg_val == oldval)
        *reg = newval;
    END_ATOMIC();
    return old_reg_val;
}
```

#### ABA问题

```c++
/* Naive lock-free stack which suffers from ABA problem.*/
class Stack {
  std::atomic<Obj*> top_ptr;
  //
  // Pops the top object and returns a pointer to it.
  //
  Obj* Pop() {
    while (1) {
      Obj* ret_ptr = top_ptr;
      if (!ret_ptr) return nullptr;
      // For simplicity, suppose that we can ensure that this dereference is safe
      // (i.e., that no other thread has popped the stack in the meantime).
      Obj* next_ptr = ret_ptr->next;
      // If the top node is still ret, then assume no one has changed the stack.
      // (That statement is not always true because of the ABA problem)
      // Atomically replace top with next.
      if (top_ptr.compare_exchange_weak(ret_ptr, next_ptr)) {
        return ret_ptr;
      }
      // The stack has changed, start over.
    }
  }
  //
  // Pushes the object specified by obj_ptr to stack.
  //
  void Push(Obj* obj_ptr) {
    while (1) {
      Obj* next_ptr = top_ptr;
      obj_ptr->next = next_ptr;
      // If the top node is still next, then assume no one has changed the stack.
      // (That statement is not always true because of the ABA problem)
      // Atomically replace top with obj.
      if (top_ptr.compare_exchange_weak(next_ptr, obj_ptr)) {
        return;
      }
      // The stack has changed, start over.
    }
  }
};
```



初始栈内元素a->b->c，T0时刻线程t1对栈进行pop操作，代码运行到`Obj* next_ptr = ret_ptr->next;`时线程切换(cur)，并将栈内元素变为a->c后线程切换回到t1，那么t1继续执行此时head会指向b，然而此时b已经被内存释放。

#### 内存回收

对于aba问题的解决办法大致思路为添加标签，使其变为a和a‘。但是仍会涉及内存回收问题。例如`pop`中代码运行到`Obj* next_ptr = ret_ptr->next;`时，此时线程切换，并且其他线程将`ret_ptr`移除，并触发了内存回收，此时线程再次切回，那么`ret_ptr`执行的是一个已被释放的内存块。

主流解决方法有：

1. Lock-Free Reference Counting: 引用计数，在进入`pop`前首先进行全局的引用计数，仅当计数值为1时可以释放内存，否则对其进行保存。
2. Lock-Free Reference Counting: 引用计数
3. Epoch Based Reclamation
4. Quiescent State Based Reclamation

#### 自旋锁资源占用问题

多线程竞争同一资源，如果自旋不成功将会一直占用cpu。解决办法时自旋一定次数或时间后退出。



### 内存模型

[c++11 内存模型](https://en.cppreference.com/w/cpp/atomic/memory_order)

c++11 提供了六种原子序操作。

#### memory_order_relaxed

不保证其他的读写顺序，仅保证自身的读写顺序。

可能出现r1=42 && r2=42。因为该原子序仅保证自身的读写顺序，不保证多线程间的顺序。从该情景中可以看出，该原子序仅保证了原子性，不会保证顺序性。因为不会保证B先与C，A先于D

```c++
// 线程 1 ：
r1 = y.load(std::memory_order_relaxed); // A
x.store(r1, std::memory_order_relaxed); // B
// 线程 2 ：
r2 = x.load(std::memory_order_relaxed); // C 
y.store(42, std::memory_order_relaxed); // D
```

典型使用场景为计数器

```c++
#include <vector>
#include <iostream>
#include <thread>
#include <atomic>
 
std::atomic<int> cnt = {0};
 
void f()
{
    for (int n = 0; n < 1000; ++n) {
        cnt.fetch_add(1, std::memory_order_relaxed);
    }
}
 
int main()
{
    std::vector<std::thread> v;
    for (int n = 0; n < 10; ++n) {
        v.emplace_back(f);
    }
    for (auto& t : v) {
        t.join();
    }
    std::cout << "Final counter value is " << cnt << '\n';
}
```



#### memory_order_release与memory_order_acquire

若线程A中存储变量带有标签`memory_order_release`，线程B中同一变量的原子加载带标签`memory_order_acquire`。则保证在线程B中能观察到线程A中写入的所有的数据。

经典使用场景为互斥锁，这里保证了p和data的值

```
#include <thread>
#include <atomic>
#include <cassert>
#include <string>
 
std::atomic<std::string*> ptr;
int data;
 
void producer()
{
    std::string* p  = new std::string("Hello");
    data = 42;
    ptr.store(p, std::memory_order_release);
}
 
void consumer()
{
    std::string* p2;
    while (!(p2 = ptr.load(std::memory_order_acquire)))
        ;
    assert(*p2 == "Hello"); // 绝无问题
    assert(data == 42); // 绝无问题
}
 
int main()
{
    std::thread t1(producer);
    std::thread t2(consumer);
    t1.join()
}
```



#### memory_order_release与memory_order_consume

若线程A中存储变量带有标签`memory_order_release`，线程B中同一变量的原子加载带标签`memory_order_consume`。则保证在线程B中能观察到线程A中写入的**依赖原子变量**的数据的顺序性。相比`memory_order_acquire`更为宽松，仅保证同样的**依赖原子变量**的数据。这种依赖具有传递性

考虑如下代码。与`memory_order_acquire`相比，`flag`依赖的`p1`可保证消费者可见，而无依赖关系的data则无法保证。

```c++
#include <thread>
#include <atomic>
#include <cassert>
#include <string>
 
std::atomic<std::string*> ptr;
int data;
std::string *p1;
 
void producer()
{
    
    p1  = new std::string("Hello");
    data = 42;
    ptr.store(p1, std::memory_order_release);
}
 
void consumer()
{
    std::string* p2;
    while (!(p2 = ptr.load(std::memory_order_consume)))
        ;
    assert(*p2 == "Hello"); // never fires: *p2 carries dependency from ptr
    assert(*p1 == "Hello"); // never fires: *p2 carries dependency from ptr
    assert(data == 42); // may or may not fire: data does not carry dependency from ptr
}
 
int main()
{
    std::thread t1(producer);
    std::thread t2(consumer);
    t1.join(); t2.join();
}
```



#### memory_order_seq_cst

原子操作默认的内存模型，对每一个变量都保证`memory_order_release与memory_order_acquire`

## memory_order_acq_rel

读-修改-写原子序，常用于对数据进行读取后修改再写回的操作。其顺序保证类似先acquire后release。

考虑如下代码，可以存在以下情况，在`producer`线程中对ptr进行存储后，线程切换到`consumer`线程，此时`release`与`acq_rel`对应，保证了`data=42`。最后切换回到producer线程,此时`acquire`与`acq_rel`，对应，保证了`data1=44`。这里的`acq_rel`同时起到了先`acquire`加载数据，再`release`的释放的作用

特别说明的`producer`线程中`acquire`和`release`也可以相对应，这样的化会造成`consummer`线程永远卡死，这里仅为举例说明。

```
#include <thread>
#include <atomic>
#include <cassert>
#include <string>
 
std::atomic<std::string*> ptr;
int data;
int data1
std::string *p1;
 
void producer()
{
    
    p1  = new std::string("Hello");
    data = 42;
    ptr.store(p1, std::memory_order_release);
    
    while (!(p2=ptr.load(memory_order_acquire)));	// 注意这里load有可能会获取ptr，从而导致consummer卡死，
	assert(data1 == 44);
}
 
void consumer()
{
    std::string* p2;
    data1 = 44;
    while (!(p2 = ptr.load(std::memory_order_acq_rel)))
        ;
    assert(*p2 == "Hello"); // never fires: *p2 carries dependency from ptr
    assert(data == 42); 	// never fires
}
 
int main()
{
    std::thread t1(producer);
    std::thread t2(consumer);
    t1.join(); t2.join();
}
```





### 参考

[c++11内存模型](https://en.cppreference.com/w/cpp/atomic/memory_order)

[知乎资料0](https://zhuanlan.zhihu.com/p/24983412)

[并发编程的艺术04-TAS自旋锁](https://zhuanlan.zhihu.com/p/125742057)

维基百科

