[toc]

# 一、为什么需要结构化日志

因为比起结构化日志，对于日志的采集、分析者而言结构化日志在日志采集、日志存储和日志分析有非结构化日志更多的优势。

1. 在日志分析上，结构化日志代表了其结构化部分日志的专业领域知识的标准与公开。基于这个专业领域知识可以进行数据业务建模、数据解析优化、数据查询优化，数据分析场景化等

2. 在日志存储上，对结构化日志的结构化部分，可以针对其结构化特性(甚至是不同的结构化部分)使用高效压缩和存储。高压缩比的最直观是降低存储，而且可以间接的优化数据查询的性能。其次是日志存储根据其结构特性可以进行进一步的存储优化为数据查询带来遍历
   * 搜索引擎往往会花费较多的时间进行IO，高压缩比意味着使用CPU代替IO以提高性能
   * 结构化特性可以优化存储结构，以加速数据查询，例如搜索引擎可以根据结构化部分的专业领域知识建立索引，进行聚合等实现物化试图等
3. 在日志采集上，结构化日志能够减少日志歧义，降低日志采集出错概率。场景化、固定化的结构化日志可以降低日志采集人员专业知识门槛。结构化的日志有利于对日志进行高压缩比的压缩，降低IO损耗。结构化日志有利于对日志采集性能进行优化
   * 非结构化日志往往会带来歧义，例如同一系统的不同模块由于业务要求不同在使用非结构化日志时有可能存在不同的字段，那么非结构化日志在采集时由于缺少对于的知识或采集人员的相关认知不足，很容易在编写采集规则时出现错漏，影响整个日志的后续采集、存储和分析，给采集系统带来破坏。而结构化日志则将对应的领域知识进行固化，采集人员则不需要关注对应的采集解析规则。
   * 结构化日志有利于进行日志压缩，目前的日志采集往往是按批处理，而同结构的日志在数据传输时存在很好的压缩能力。例如同一模块日志是同构的，采用列式存储组织多条日志，可以高效的进行压缩，从而减少数据传输的数据量，加快IO能力。提高数据采集性能
   * 结构化日志在采集时可以通过其shacma加速日志的采集，非结构化日志往往需要对日志在字符串层面的进行解析，而结构化的日志可以采取一定的序列化手段，避免在字符串层面进行解析，而是直接通过schema进行解析。在数据采集、传输到数据接收解析三个过程中，往往日志接收会是性能瓶颈，因此直接通过shema进行解析可以加速整个采集过程。例如arrow这个数据交换技术，其数据序列化和反序列化仅需要处理其数据头部的shcema，从而构建出对应的数据操作对象，避免了大量的字节处理。类似的逻辑还能在IPV6在IPV4上的数据报头优化上看到。



# 二、什么是结构化日志

网上一些文章说一些传统的日志，通过空格等分隔符进行分隔，输出格式自由定义的扁平化日志是比较典型的非结构化日志。例如

```
%d{yyyy-MM-dd HH:mm:ss.SSS} %level ${application_name} trace=%X{X-B3-TraceId},span=%X{X-B3-SpanId} <%t> %c{40} - %msg%n
```

而结构化的日志则是使用json等格式进行处理后的日志。个人存在不同的观点。结构化日志和非结构化日志的区别在于是否存在专业领域的知识，而不是其是否用json或空格分隔。因为毕竟使用json的日志，也是使用冒号和双引号进行分割的日志。给人带来这种误差的原因在于json格式的日志带有确切的key值，这些key值往往代表了对应的专业领域知识。而以空格等分隔符处理的扁平化日志则没有包含自身的专业领域知识，而是隐含起来由采集、分析者赋予，而采集、分析者在确不一定能够赋予。因为日志可以从不同的模块、不同的系统中采集，大家难以形成统一的共识。而这种情况在分布式系统下更为常见。

考虑一下两条opentelemetry log日志。它可以说是基于opentelemetry标准下的结构化日志。开发者可以基于opentelemetry 进行优化，加速日志的采集、传输、解析与存储。但对其的优化仅限于opentelemetry 级别的优化，而在日志内其实包含了其他专业领域的知识，例如第一条日志中的`Attributes`http请求字段，第二条日志中的`Body`字段，这两个字段对opentelemetry标准来说是非结构化的，因为在进行存储优化时只能优化到opentelemetry设计的字段，而对字段内容无法进一步利用其专业领域知识，例如使用日志采集端使用opentelemetry标准时，其列式存储保存日志最多只能下专到opentelemetry 设计字段，字段内容仍需要以字符串保存。但实际的场景中往往需要对字段内容进一步的进行分析、处理，甚至是优化。而且例子中的两条日志，不用json使用分隔符划分就不能表示吗？

据这个例子的本意在于说明个人认为**结构化日志是相对的，其设计也应该是分层的**。

```json
{
  "Timestamp": 1586960586000, // JSON needs to make a decision about
                              // how to represent nanoseconds.
  "Attributes": {
    "http.status_code": 500,
    "http.url": "http://example.com",
    "my.custom.application.tag": "hello",
  },
  "Resource": {
    "service.name": "donut_shop",
    "service.version": "2.0.0",
    "k8s.pod.uid": "1138528c-c36e-11e9-a1a7-42010a800198",
  },
  "TraceId": "f4dbb3edd765f620", // this is a byte sequence
                                 // (hex-encoded in JSON)
  "SpanId": "43222c2d51a7abe3",
  "SeverityText": "INFO",
  "SeverityNumber": 9,
  "Body": "20200415T072306-0700 INFO I like donuts"
},
{
   "Timestamp": 1586960586000,
   "Attributes":{
      "http.scheme":"https",
      "http.host":"donut.mycie.com",
      "http.target":"/order",
      "http.method":"post",
      "http.status_code":500,
      "http.flavor":"1.1",
      "http.user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36",
   },
   "Body": {
    "i": "am",
    "an": "event",
    "of": {
      "some": "complexity"
    }
  }
}
```



# 三、结构化的日志结构

## 为何要分层

结构化日志是专业领域知识定义的，但如果对同一领域存在多种标准，则会影响使用者的同一认知，因此往往也会期望一个统一的标准，但统一的标准未必能满足所有人的业务场景，因此可以对这种统一的标准进行分层设计，不同角度的使用者在不同的层面上进行，但同一层面的使用者有相同的标准。

这种思想类似于操作系统的分层，网络osi模型等上层使用者不需要关心下层使用者的详细逻辑，下层为上层提供接口。

那么以`f`代表每一层日志的处理函数，那么一个最终结构化日志m的公式如下：

`m = f1(x, f2(y, f3(z,..........fn(j) ) ) ) = f1·f2·f3·......·fn(x,y,z,....j)`

以`ft`代表每一层日志的处理函数逆处理，对结构化日志的处理方案将会变为

`info = ft1·ft2·ft3·......·ftn(m)`

对结构化日志的采集、解析者仅需要负责其对应层级的处理。根据实际的使用业务场景，对结构化日志进行优化。如果`f1`代表的是日志的序列化，则日志的接收者仅需要进行`m' = ft1(m)`即可完成接收，对后续数据的进一步处理则由下一个层级的使用者完成。



## 分布式系统上进行结构化日志分层设计sdk

### 生成

对日志的生成和解析分层进行，则使用者仅需要关注自身所在层该如何使用。以下胡诌，仅作参考

1. 第一层f1为数据输出层，f1根据上层传递的日志决定日志的输出目的地，完成日志输出行为，例如目的地为标准输出或某个文件，输出方式为http或tcp，分批或流式。与实际实现以及业务划分有关
2. f2数据压缩层，将数据进行压缩处理。与实际实现有关
3. f3为数据序列化层，日志序列化层，对日志进行序列号或某些优化，有时候也会与f2合并。以实现有关
4. f4整体日志类型层，在这一层决定整个结构日志的第一个总体类型，甚至是数据结构的版本号等整体上下文信息，例如标明该日志类型为opentelemetry 
5. f5模块局部日志类型层，在f4层的约束下，填写日志，但同时模块可能会由自身的专业性知识可以额外定义。例如使用opentelemetry时可以设置日志为trace类型或log类型，又或者是metric类型，又或者是复合类型。
6. fn，后续的每一层都可以继续基于f5进行进一步定义和处理。例如在f6定义系统模块名称，f7定义系统模块日志级别和f8日志的格式，f8定义业务相关字段信息。

通过分层的固化专业领域知识并标准化，便于进行优化，也有利于上层应用业务的扩展。

以下是乱写的分层，仅作参考

1. 在实现上可以考虑使用系统上下文获取本层使用者应该使用的函数处理模块。例如一个后端服务启动时，完成`f1'=f1·f2·f3`的初始化。接收请求后从全局上下文中获取`f1'`，需要设置trace类型的日志时完成`f2'=f1'·f4`的配置，业务继续下砖时从上下文中获取`f2`使用，需要继续传递时封装`f2'`实现其业务。
   * 基于这种思想，那么f1到f3考虑交给AR进行设计，因为这个涉及采集和传输以及可能涉及到日志存储的规划。

3. 如果f4使用[OpenTelemetry Log Data Model](https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/logs/data-model.md)作为目前的类型应该考虑在f4之前的层中增加日志协议的标识。f4实现OpenTelemetry向上层提供`trace`,`log`,`metric`和一些符合类型的日志器
   * 上层应用基于f4提供的OpenTelemetry可以填写OpenTelemetry规范的字段。
4. f5后续与日志内容相关，可以交由各个系统进行进一步的日志业务处理，用于填写自身业务日志，例如f5可以决定将系统日志填写到body，应用进程填写到Resource，而请求的上下文填写到Attributes。f5可以考虑处理在微服务级别的约束
   * 当然如果可以这里仍然可以i规范，例如在f5会自动填充进程和请求的上下文信息，向使用者提供body的权利
   * 例如进程上下文属性可以包含模块名、代码调用栈，并且可以自动创建metric指标
   * 请求上下文属性可以包含请求的详细描述，行为，甚至从上下文可以自动创建trace
   * body的填写权利交由接口开发者



### 解析

在采集和分析模块时每确定一层的设计，则可以考虑对其专业化领域进行优化处理，如超出使用者可理解范围则将对应部分以字符串或字节数组的方式处理，交由下一层使用者进一步分析。例如假设在这里定义了5层，但某个微服务的某个子模块进一步定义了新的日志数据层，则应由对应模块澄清数据模型，并在处理该部分日志时再交由对应层处理。

对结构化日志的处理，在f5级别情况下可以考虑通过schema on write(例如elk中的logstash，fluenbit，物化视图等)的处理解析，对f6以上视实际情况决定是否在解析数据流中增加新的数据处理模块，增加数据解析流程(涉及新的数据存储设计和数据路由、负载设计)，或通过 schema on read(例如spl)的方式提供给需要该层日志的分析者。

一个例子就是一些java产品其持久化日志是人力不可直接查看，而是需要对应工具。





