## 测试方案
### 测试前置
1. 测试数据：HDFS...
2. 测试平台：centos7.4 4C16G
2. 测试指标：事件吞吐率，数据量吞吐率，进程(容器)cpu、Mem、IO

3. 测试目的：测试logstash进行多行事件处理，时间戳、字段提取性能与资源使用情况

4. 测试工具：docker，cadvisor && Prometheus，psutil，dstat && dstat自动脚本，time，top

5. 参数设置:
pipeline.workers=8 （影响filter和output处理线程数量）
jvm.heap = 8GB (官方推荐不大于8G且小于物理内存)
Xms == Xmx

### 测试点:
logstash以下行为的性能
1. 多行事件处理
2. 正则匹配提取字段
3. 时间识别
4. event转换输出效率
5. event转换为json输出效率

### 测试方案
logstash属于长进程任务，无法在数据处理结束后自动停止任务，并且数据处理时间往往由于程序内部队列的关系不等于数据发送时间。因此通过在数据发送前后发送特殊输入，在特殊文件中生成日志，最后计算开始和结束日志时间差计算时长。

进程处理过程中的性能指标采集和分析方案：
<!-- * 第一种, dstat采集指标，通过某些工具分析数据，或自行编写脚本进行分析。
* 第二种，prometheus+cadvisor+grafana平台采集指标并图形界面分析 -->
通过psutil每隔1s采集一次进程状态，当进程结束后计算给出总体进程状态，计算给出进程的cpu，mem和io信息，为各个指标运行趋势绘图。并在sqlite3中保存每次采集的信息，在需要时可以重新查看或分析绘图。

## 测试一
### 测试用例说明
1. 文件输入(无codec): 配置文件仅包含文件接收，目的为测试文件读取性能
    * 测试数据源接收包含一个隐藏因素，数据在程序内部转换为event的效率
2. 文件输入: 配置文件中包含文件接收和多行合并配置，目的是获取文件读取加上多行合并的性能，从而计算出多行合并的性能
3. 文件输入+grok提取字段: 数据源配置文件中包含文件接收和多行合并配置，filter/transform包含基于正则的字段提取。目的是测试正则提取字段的性能
    * 隐含的的性能影响因素有event在多个数据处理对象间传递的性能，event对象操作的性能。
4. 文件输入+grok提取字段+json输出: 目的在于测试程序内部event数据转换为效率。
    * 数据输出插件主要的工作有event转换为输出协议格式，以及输出源的接收能力。因此使用文件输出作为测试其event转换能力的输出
5. 文件输入+多行合并处理+json输出: 目的是测试vec中多行合并行为的性能

### logstash测试表现

|用例|吞吐量(MB/S)|事件吞吐量(条/s)|cpu(%)|memory(MB)|
|:---:|:---:|:---:|:---:|:---:|
|1|5.3|23647|172.2|739.7|
|2|3.52|15693|153|742.3|
|3|3.70|16525|256.6|846.1|
|4|3.94|17584——17879|242——258|843|

根据表格可以发现，在当前测试用例中，主要性能瓶颈在于logstash的文件读取input插件和多行合并的codec中。
简单的文本读取只能达到5.3MB/s,而根据前两个用例计算，logstash的多行合并约为10.48MB/s。
由于input插件性能问题，该测试结果无法体现logstah的正则和事件转换性能瓶颈。需要设计新的测试用例，增加logstash的接收能力以测试logstash的正则提取字段、时间识别和event转换的最终极限性能

### vector测试表现
|用例|吞吐量(MB/S)|
|:---:|:---:|
|5|16.33|
结合测试二的用例5结果发现，即使加上多行合并处理，由于文件输出的性能为17.9MB/s，两者相比考虑到机器稳定性和误差的影响，因此这个性能测试结果可能无法体现出多行合并的性能。


## 测试二
### 测试用例
1. TCP接收: 单纯的tcp接收，不额外配置codec配置，目的在于测试出数据源接收极限
2. TCP接收+grok提取字段: 测试正则提取字段性能
    * 隐含的的性能影响因素有event在多个数据处理对象间传递的性能，event对象操作的性能。
3. TCP接收+grok提取字段+json输出: 测试事件转换性能
4. TCP接收+null: 该测试用例仅包含数据接收和空设备输出两个数据处理单元，目的在于对比用例1，判断vector和logstash并行部分是否有足够的并行粒度。
5. TCP接收+文件输出: 该测试用例仅包含数据接收和文本输出两个数据处理单元，目的时测试并行处理单元的并行粒度和事件转换为文本的性能

### logstash测试表现
|用例|吞吐量(MB/S)|事件吞吐量(条/s)|cpu(%)|memory(MB)|
|:---:|:---:|:---:|:---:|:---:|
|1|17.68|76471.05|253|839.2||
|2|12.79|55301.77|399|851.3|
|3|9.5|38914|412.0|847.51|
|4|17.68|76471.05|253|856.7|
|5|15.86|

logstash的input和filter处理分别在不同的线程中，通过内部队列进行数据传递，如果两个模块能够有效的并行，那么可以认为接收+数据处理的整个过程消耗时间基本取决于最慢的模块。因此根据表格中第一第二行结果，可以认为logstash的grok正则处理大约为12.79MB/S

### vector测试表现
|用例|吞吐量(MB/S)|事件吞吐量(条/s)|cpu(%)|memory(MB)|
|:---:|:---:|:---:|:---:|:---:|
|1|89.85|388623.36|323|33.6|
|2|13.49|58341.3|324.1|42|
|3|12.1|52369.72|364.3|28.47|
|4|85|370406|403.7|25.7|
|5|17.9|

通过vector和logstash测试用例一可以确定在logstash的input接收极限为17.68MB/s，当进行用例2和用例3的测试时主要性能影响为正则提取字段。
对比用例1和用例4，可以得出结论，性能测试数据管道只含有两个处理单元的情况下，拥有各个处理单元具有良好的并行度。用例2结合该结论可以认为vector的正则提取字段性能约为13.49MB/s。
用例4和用例5可以说明在vector中事件的转换也是一个重要的性能影响因素
从用例1和用例4中还可以发现，由于用例4不能存在event转换为文本的开销，因此两个用例的性能差异除了一定的误差外，大部分是vector两个处理单元的数据传递以及处理单元的执行调度带来的额外开销也会有一定的影响。

## 测试结果
|Metric|logstash|vector|
|:---:|:---:|:---:|
|TCP接收吞吐(MB/S)|17.68|89.85|
|TCP接收吞吐(条/s)|76471.05|388623.36|
|正则提取字段(MB/s)|12.79|13.49|
|正则提取字段(条/s)|55301.77|58341.3|
|多行合并(MB/s)|10.48|×|
|多行合并(条/s)|45313.73|×|
|*event转换含文件IO(MB/s)|15.86|17.9|
|*event转换效率含文件IO(条/s)|68737.15|77413|
|cpu占用|200%-400%|300%-400%|
|内存占用|700——900MB|100MB以内|