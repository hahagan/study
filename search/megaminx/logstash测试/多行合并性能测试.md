## [测试方案](http://confluence.aishu.cn/pages/resumedraft.action?draftId=82073796&draftShareId=cdeaf975-e275-454b-9db1-7e1f78a2dcf9#测试方案)

### [测试前置](http://confluence.aishu.cn/pages/resumedraft.action?draftId=82073796&draftShareId=cdeaf975-e275-454b-9db1-7e1f78a2dcf9#测试前置)

1. 测试数据：HK数据
2. 测试平台：
3. 测试指标：服务事件吞吐率，服务数据量吞吐率，服务内部延时(能力不足，不测)，进程cpu、Mem。
4. 测试目的：测试logstash进行多行事件处理，时间戳、字段提取性能与资源使用情况
5. 测试工具：docker，cadvisor && Prometheus，aly.py脚本监控进程状态
6. 了解logstash和vector数据流结构(详情查看[logstash功能分析]())

### [测试点](http://confluence.aishu.cn/pages/resumedraft.action?draftId=82073796&draftShareId=cdeaf975-e275-454b-9db1-7e1f78a2dcf9#测试点)

logstash以下功能的性能

1. 多行合并性能
2. kafka读取性能
3. kafka写入性能
4. 复杂情况(HK数据流)下logstash性能和资源占用
5. http/TCP接收能力
6. es输出能力

### [测试方案](http://confluence.aishu.cn/pages/resumedraft.action?draftId=82073796&draftShareId=cdeaf975-e275-454b-9db1-7e1f78a2dcf9#测试方案-1)

#### 测试目录划分

```
Readme	## 测试说明，必填
tools	## 测试使用工具目录
	|---- aly.py
	|---- send.py
	|---- ......
usecase	## 测试用例目录
	|--- case1
		|---- Readme	## 用例说明，可选
		|---- datas		## 测试需要数据，可选
		|---- settings	## 配置项，可根据需要划分
			|---- logstash.conf
		|---- reports	## 用例测试报告
		|---- do_test.sh	## 可选，快速测试脚本	
	|---- ....
reports	## 用例综合测试报告，必填
datas	## 数据存储目录
```

#### 测试指标获取

测试采用数据定量测试。logstash不开启自动更新。

测试时采用先生成数据进行定量，在进行数据发送的方式进行，以获得确切的原始数据量。数据定量测试的缺点是可能比较费时，但指标获取简单。

吞吐通过服务实际执行实际时间t计算。数据大小可根据生成的数据大小识别。cpu和memory指标可以通过aly.py脚本监控进程获得。

```
事件吞吐量 = 事件数量 ÷ t
数据吞吐量 = 数据大小 ÷ t
```

如果有兴趣，可以自行考虑定时测试的方案，需要考虑如何获取运行时间内的原始数据和初始事件数，处理结束后事件数。

#### 测试用例

以下为测试用例简单介绍，具体测试人员根据测试目录划分进行重写。

##### 用例一

描述： 测试logstash的http/TCP接收能力，需要压出logstash的极限接收能力。

参与组件：压测工具，logstash

logstash配置：logstash配置中仅含input插件。

目的：测试logstash的最大接收能力，同时得出相应的压测工具

##### 用例二

描述：测试logstash的kafka写入能力

参与组件：压测工具，logstash，kafka实例

logstash配置：配置中仅含input和output，可以认定为HK环境下的logstash-input容器订阅配置(可进行优化，优化需要记录说明)

目的：测试logstash到kafka的输出能力，同时得出HK环境下的数据接收能力性能测试报告

##### 用例三

描述：测试logstahs读取kafka性能

参与组件：logstash，kafka

logstash配置：仅含kafka的input组件配置

目的：测试出logstash的kafka读取性能，对比http/TCP性能，选择性能最好的组件作为后续的性能测试中选择的数据源。

##### 用例四

描述：测试logstash的多行合并性能极限。使用压测工具或kafka作为输入，如果使用kafka作为输入则需要在kafka内预先存有一定数据。数据内容为对N种数据可进行多行合并的数据，数据内多行合并占比为100%

参与组件：kafka/压测工具，logstash

logstash配置：input数据源接收一种数据，filter内仅含一种多行合并处理规则

目的：测试出logstash分别对几种不同的数据进行多行合并的最差性能。得出测试最简环境下单种数据的多行合并性能，并可以作为用例六的性能分析和调优的依据

##### 用例五

描述：测试HK混合数据下数据处理的性能。测试方法与用例四相同，区别在logstash的配置采用HK的logstash-filter容器订阅配置，数据内容为HK的混合数据。

参与组件：kafka/压测工具，logstash

logstash配置：HK的数据解析规则，不包含output插件配置

目的：测试出logtash在HK环境下的性能，

##### 用例六

描述：测试HK混合数据下加多行合并数据处理的性能。测试方法与用例四相同，区别在logstash的配置采用HK的logstash-filter容器订阅配置以及需要进行的多行合并规则，数据内容为HK的混合数据。

参与组件：kafka/压测工具，logstash

logstash配置：HK的数据解析规则，不包含output插件配置

目的：测试出logstash在HK环境下进行了多行合并后对性能的影响。

